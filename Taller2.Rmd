---
title: "Taller 2"
output: html_notebook
---

**Daniel Alejandro Leon Ortiz - 2190064**

**Yesid Romario Gualdrón Hurtado - 2190052**

**Daniel Adrián González Buendía - 2191943**

```{r}
K=read.table(file='kittiwak.txt',header=TRUE)
P=read.table(file='physical.txt',header=TRUE)

rls <- function(x,y){
  graphics.off()
  mx=mean(x)
  my=mean(y)
  b1=sum((x-mx)*(y-my))/sum((x-mx)^2)
  b0=my-b1*mx
  if (b1<0){
    plot(x,y, xlim=c(min(0,x),max(x)),ylim=c(min(y),ceiling(max(y,b0))))
    mtext(paste0('y=',round(b0,6),round(b1,6),'x'), side = 3)}
  else{
    plot(x,y, xlim=c(min(0,x),max(x)),ylim=c(min(floor(b0),y),ceiling(max(y))))
    mtext(paste0('y=',round(b0,6),'+',round(b1,6),'x'), side = 3)}
  curve(b0+b1*x,add=TRUE,col='red')
  return(c(b0,b1))} #y=b0+b1x

rls_est <- function(x,y,x0){
  b0=rls(x,y)[1]
  b1=rls(x,y)[2]
  graphics.off()
  y_est=b0+b1*x0
  plot(x,y)
  points(x0,y_est,col='red')
  abline(h=y_est,v=x0,col='blue')
  curve(b0+b1*x,add=TRUE,col='red')
  return(y_est)
}

rls_var <- function(x,y){
  b0=rls(x,y)[1]
  b1=rls(x,y)[2]
  graphics.off()
  n=length(x)
  e2=sum((y-(b1*x+b0))^2)
  return(c(e2/n,e2/(n-2))) 
} #Sesgado (est. de max. veros.) e insesgado (var. res.)

rls_ci <- function(x,y,ci){
  n=length(x)
  S2X = var(x)
  S2R = rls_var(x,y)[2] #Usando la varianza residual insesgada
  if (n>=30)
    q=qnorm((1-ci)/2,lower.tail = 0)
  else
    q=qt((1-ci)/2,df=n-2,lower.tail = 0)
  b0_est=rls(x,y)[1]
  b1_est=rls(x,y)[2]
  graphics.off()
  l_b1=b1_est-q*sqrt(S2R/((n-1)*S2X))
  u_b1=b1_est+q*sqrt(S2R/((n-1)*S2X))
  
  mx=mean(x)
  l_b0=b0_est-q*sqrt(S2R*(1/n+mx^2/((n-1)*S2R)))
  u_b0=b0_est+q*sqrt(S2R*(1/n+mx^2/((n-1)*S2R)))
  return(list('b0'=c(l_b0,u_b0),'b1'=c(l_b1,u_b1)))
}

rls_icp <- function(x,y,ci,x0){
  n=length(x)
  S2X = var(x)
  S2R = rls_var(x,y)[2] #Usando la varianza residual insesgada
  if (n>=30)
    q=qnorm((1-ci)/2,lower.tail = 0)
  else
    q=qt((1-ci)/2,df=n-2,lower.tail = 0)
  graphics.off()
  icp=c(q*sqrt(S2R*(1+1/n+((x0-mean(x))^2/((n-1)*S2R)))))
  return('intervalo'=icp)
}

rls_err <- function(x,y){
  b0=rls(x,y)[1]
  b1=rls(x,y)[2]
  graphics.off()
  e=y-(b1*x+b0)
  return(e)
}

rls_cd <- function(x,y){
  b0=rls(x,y)[1]
  b1=rls(x,y)[2]
  graphics.off()
  y_est=b1*x+b0
  my=mean(y)
  SCE=sum((y-y_est)^2)
  STCC=sum((y-my)^2)
  R2=1-SCE/STCC
  return(R2)
}


```
![](p1.png)
```{r}
x_K=log(K$Area)
y_K=K$Population
rls(x_K,y_K)
model <- lm(y_K~x_K)
```
![](p1a.png)
```{r}
e_K=rls_err(x_K,y_K)
sprintf("Valor promedio del residuo: %s", mean(abs(e_K)))
plot(x_K,e_K,col='red')  #Scatterplot de la distribución del error
abline(h=0,col='green')
segments(x_K,0,x_K,e_K)  
```
Se observa que los residuos en su mayoría son bajos a excepción de dos valores atípicos y otros que están un poco dispersos.
```{r}
boxplot(rls_err(x_K,y_K)) #Boxplot de la distribución del error
```
Se pueden observar más claramente esos valores atípicos y la mediana que tiene un valor negativo cercano a cero.
![](p1b.png)
```{r}
sprintf("Varianza de la variable independiente: %s", rls_var(x_K,y_K)[1])
sprintf("Coeficiente de determinación: %s", rls_cd(x_K,y_K))
sprintf("Varianza residual: %s", rls_var(x_K,y_K)[2])
graphics.off()
```
En este caso se usa el estimador de máxima verosimilitud para hacer el cálculo de la varianza de la variable independiente, aunque este es un estimador sesgado y como era de esperarse, y para la varianza residual se usa el estimador insesgado de la varianza poblacional. Se observa que el primero es menor que el segundo, como era de esperarse, debido a sus respectivos denominadores.
![](p1c.png)
```{r}
#
x_icp <- seq(1, 100, length = 10)
y_icp <- c()
for(x_value in x_icp){
  y_icp <- c(y_icp, rls_icp(x_K, y_K, 0.95, x_value))
}
plot(x_icp, y_icp)
mean(x_K)
```

Encontramos que el ajuste que proporciona la regreción lineal no es muy bueno basandonos en el coeficiente de determinación.
Tambien encontramos, como se puede ver en la gráfica, que para islas pequeñas los intervalos de confianza son pequeños y para las islas grandes crece este intervalo.
Esto nos indica que para hacer una predicción con una confianza del 95% no podremos acotar las respuestas en un intervalo pequeño.


![](p1d.png)
```{r}
x_k=log(K$Area[K$Population<=10000])
y_k=K$Population[K$Population<=10000]
mx=mean(x_k)
my=mean(y_k)
b1=sum((x_k-mx)*(y_k-my))/sum((x_k-mx)^2)
b0=my-b1*mx
plot(x_K,y_K, xlim=c(min(0,x_K),max(x_K)),ylim=c(min(floor(b0),y_K),ceiling(max(y_K))))
mtext(paste0('y=',round(b0,6),'+',round(b1,6),'x'), side = 3)
curve(b0+b1*x,add=TRUE,col='red')
```
```{r}
sprintf("Coeficiente de determinación: %s", rls_cd(x_k,y_k))
n=length(x_K)
e2=sum((y_K-(b1*x_K+b0))^2)
sprintf("Varianza residual: %s", e2/(n-2))
b0=rls(x_k,y_k)[1]
b1=rls(x_k,y_k)[2]
e_k=y_K-(b1*x_K+b0)
sprintf("Valor promedio del residuo: %s", mean(abs(e_k)))
graphics.off()
plot(x_K,e_k,col='red')  #Scatterplot de la distribución del error
abline(h=0,col='green')
segments(x_K,0,x_K,e_k)  
```
Se observa un error mucho más grande en el caso de los valores atípicos pero menor en el caso de los otros valores, lo cual hace que en última instancia, y comparando sus promedios (2214.7535 y 1883.6677), sea mejor hacer uso de la regresión que descarta esos valores atípicos, pero dependiendo del umbral que se le imponga al descartar, y de los datos en general, podría suceder todo lo contrario. En términos de varianza, se tiene 11866803.91 y 15257149.97, por lo que se concluye una mayor dispersión de los errores pero eso no es necesariamente algo negativo. Considerando que el coeficiente de determinación expresa numéricamente la proporción de la variabilidad del modelo, donde el valor esperado sería 1, y que los obtenidos por los modelos son 0.314688 y 0.304028, se tienen valores muy bajos pero el mejor modelo tiene una mayor variabilidad.
![](p2.png)
```{r}
y_2 = P$Mass
info_2 = lm(y_2~P$Fore+P$Bicep+P$Chest+P$Neck+P$Shoulder+P$Waist+P$Height+P$Calf+P$Thigh+P$Head)
print(info_2$coefficients)
```
Utilizando una notación de iniciales se obtendría el modelo de regresión lineal múltiple: 

  $$\begin{eqnarray} m=`r toString(info_2$coefficients[1])`+`r toString(info_2$coefficients[2])`f+`r toString(info_2$coefficients[3])`b+`r toString(info_2$coefficients[4])`c \\ `r toString(info_2$coefficients[5])`n`r toString(info_2$coefficients[6])`s+`r toString(info_2$coefficients[7])`w+`r toString(info_2$coefficients[8])`h \\ +`r toString(info_2$coefficients[9])`ca+`r toString(info_2$coefficients[10])`t`r toString(info_2$coefficients[11])`he  \end{eqnarray}$$
![](p2a.png)
```{r}
plot(y_2,info_2$residuals,col='red')  #Scatterplot de la distribución del error
abline(h=0,col='green')
segments(y_2,0,y_2,info_2$residual) 
```
![](p2b.png)
```{r}
y_2_2 = (P$Mass)^(1/3)
info_2_2 = lm(y_2_2~P$Fore+P$Bicep+P$Chest+P$Neck+P$Shoulder+P$Waist+P$Height+P$Calf+P$Thigh+P$Head)
plot(y_2_2,info_2_2$residuals,col='red')  #Scatterplot de la distribución del error
abline(h=0,col='green')
segments(y_2_2,0,y_2_2,info_2_2$residual)
```

```{r}
#plot(y_2,info_2_2$residuals,col='red')  #Scatterplot de la distribución del error
#abline(h=0,col='green')
#segments(y_2,0,y_2,info_2_2$residual)
```
Encontramos que aunque la distribución de los residuos es la misma, el valor de $y$ se reduce mucho en la segunda gráfica lo que indica que esta gráfica provee una mejor regresión para los datos dados.
![](p2c.png)
```{r}
boxplot(info_2$residuals)
```
```{r}
boxplot(info_2_2$residuals)
```
En el primer modelo se observa una distribución de erorres aparentemente sin valores atípicos, en lo cual difiere con el segundo modelo, ya que este presenta un valor atípico de 0.07840938. De acuerdo a la ubicación de la mediana en el segunmo modelo, se puede decir que este está sesgado hacia los valores positivos. Analizando los diagramas de caja se evidencia una menor dispersión de los datos en el primer modelo, por lo que se podría decir que el primer modelo tiene una mejor predicción de los datos al no contener outliers ni sesgos.